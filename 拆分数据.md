# 目录
* [背景介绍](#背景介绍)
* [ONT数据](#ont数据)
* [微生物16S拆分](#微生物16S拆分)


## 背景介绍
看来数据拆分在生信中还是很常见的，一般的原因是一个样品往往不需要这么多数据量，常见的有illumina混库测序、16S测序、PacBio测序、ONT测序和10X genomics测序一般都涉及到数据拆分。因此有必要记录下相关数据的拆分过程。

## ONT数据
刚好要写一个ONT的组装流程，正好把拆分这一步写到流程中去。

## 微生物16S拆分
关于拆分脚本：
1. 目前海外16S自动建库拆分
/ifs/TJPROJ3/GB_MICRO/PJ_GB/seq/auto/1000/jixianhong/H202SC20020895.DMP.PE250.20200717.X202SC20020895-Z01-F003/Demultiplex/FDMP20H002818-1a_AHLVLYDRXX_L2/ 
流程中原来的python
采取用数组来做遍历 in alist (alist:是一个数组)
时间消耗：
real	248m44.810s
user	240m3.310s
sys	0m13.390s

2. 采取用数组来做遍历 in aset (aset:是一个集合)及避免频繁输出结果：
修改后的python：
/ifs/TJPROJ3/GB_MICRO/USER/zhangjinbo/test/00.chaifen/version2/
时间消耗：
real	39m51.362s
user	39m41.635s
sys	      0m4.309s

3. 修改去做barcode序列比较，算 Hamming Distance Between Two Strings，约300行
/ifs/TJPROJ3/GB_MICRO/USER/zhangjinbo/test/00.chaifen/version4/
时间消耗：
real	31m19.733s
user	31m8.571s
sys		0m3.366s

4. 国内的perl脚本，海外带分析脚本
将近一千行, 以后维护看懂比较困难，但是海外国内都是用这个，然后还考虑了数量等其他方面，功能强大
/PUBLIC/source/HW/MICRO/16S/16S_pipeline_V3.1/lib/01.BCQC/Data_filter_v1.1.pl
时间消耗：
real	32m34.036s
user	16m30.826s
sys		1m9.704s

下周讨论下，用perl还是python的版本，perl的版本用的多，而且功能多。python的后面好维护，而且可以后面改成多线程。


